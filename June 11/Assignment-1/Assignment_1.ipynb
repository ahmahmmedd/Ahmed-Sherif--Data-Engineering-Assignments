{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30ea484d-0704-489c-a541-442abedcdfa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0x7f14e821ba50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"azureToColab\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76825784-c667-4666-afc5-0f6de9967269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+\n|  Name| Department|Salary|\n+------+-----------+------+\n|Ananya|         HR| 52000|\n| Rahul|Engineering| 65000|\n| Priya|Engineering| 60000|\n|  Zoya|  Marketing| 48000|\n| Karan|         HR| 53000|\n|Naveen|Engineering| 70000|\n|Fatima|  Marketing| 45000|\n+------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Ananya\", \"HR\", 52000),\n",
    "(\"Rahul\", \"Engineering\", 65000),\n",
    "(\"Priya\", \"Engineering\", 60000),\n",
    "(\"Zoya\", \"Marketing\", 48000),\n",
    "(\"Karan\", \"HR\", 53000),\n",
    "(\"Naveen\", \"Engineering\", 70000),\n",
    "(\"Fatima\", \"Marketing\", 45000)]\n",
    "columns = [\"Name\", \"Department\", \"Salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880708b8-94f7-4f85-bf94-f31529a710db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exercise Set 1: Basics"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+\n|  Name| Department|Salary|\n+------+-----------+------+\n|Ananya|         HR| 52000|\n| Rahul|Engineering| 65000|\n| Priya|Engineering| 60000|\n|  Zoya|  Marketing| 48000|\n| Karan|         HR| 53000|\n|Naveen|Engineering| 70000|\n|Fatima|  Marketing| 45000|\n+------+-----------+------+\n\nroot\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Salary: long (nullable = true)\n\nNumber of employees:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Display all records in the DataFrame.\n",
    "df.show()\n",
    "#2. Print the schema of the DataFrame.\n",
    "df.printSchema()\n",
    "#3. Count total number of employees.\n",
    "print(\"Number of employees:\")\n",
    "df.select(\"name\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af2d0b8-1c01-4985-93fd-754297e8d6d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exercise Set 2: Column Operations"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Ananya|         HR| 52000| 7800.0|59800.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Ananya|         HR| 52000| 7800.0|59800.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#4. Add a new column Bonus which is 15% of Salary.\n",
    "df = df.withColumn(\"Bonus\", df.Salary * 0.15)\n",
    "df.show()\n",
    "#5. Add a new column NetPay = Salary + Bonus.\n",
    "df=df.withColumn(\"NetPay\", df[\"Salary\"] + df[\"Bonus\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d645ad-aa1d-4b45-982d-bb2d22645a17",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filtering and Conditions"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Ananya|         HR| 52000| 7800.0|59800.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Naveen|Engineering| 70000|10500.0|80500.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#6. Display only employees from the “Engineering” department.\n",
    "df.filter(df.Department == \"Engineering\").show()\n",
    "\n",
    "#7. Display employees whose salary is greater than 60000.\n",
    "df.filter(df[\"Salary\"] >60000).show()\n",
    "\n",
    "#8. Display employees who are not in the “Marketing” department.\n",
    "df.filter(df[\"Department\"] != \"Marketing\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bde5c3ec-c0f0-45df-be9a-3d2f1f7905cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exercise Set 4: Sorting and Limiting"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Naveen|Engineering| 70000|10500.0|80500.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n+------+-----------+------+-------+-------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|Naveen|Engineering| 70000|10500.0|80500.0|\n| Rahul|Engineering| 65000| 9750.0|74750.0|\n| Priya|Engineering| 60000| 9000.0|69000.0|\n| Karan|         HR| 53000| 7950.0|60950.0|\n|Ananya|         HR| 52000| 7800.0|59800.0|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#9. Show top 3 highest paid employees.\n",
    "df.orderBy(df[\"Salary\"].desc()).limit(3).show()\n",
    "\n",
    "#10. Sort the data by Department ascending and Salary descending.\n",
    "df.orderBy(df[\"Department\"].asc(), df[\"Salary\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a543e9-43aa-4c12-97d3-99b4d11a9d72",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exercise Set 5: String and Case Logic"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------+-------+-------+------+\n|  Name| Department|Salary|  Bonus| NetPay| Level|\n+------+-----------+------+-------+-------+------+\n|Ananya|         HR| 52000| 7800.0|59800.0|   Mid|\n| Rahul|Engineering| 65000| 9750.0|74750.0|Senior|\n| Priya|Engineering| 60000| 9000.0|69000.0|   Mid|\n|  Zoya|  Marketing| 48000| 7200.0|55200.0|Junior|\n| Karan|         HR| 53000| 7950.0|60950.0|   Mid|\n|Naveen|Engineering| 70000|10500.0|80500.0|Senior|\n|Fatima|  Marketing| 45000| 6750.0|51750.0|Junior|\n+------+-----------+------+-------+-------+------+\n\n+------+-----------+------+-------+-------+\n|  Name| Department|Salary|  Bonus| NetPay|\n+------+-----------+------+-------+-------+\n|ANANYA|         HR| 52000| 7800.0|59800.0|\n| RAHUL|Engineering| 65000| 9750.0|74750.0|\n| PRIYA|Engineering| 60000| 9000.0|69000.0|\n|  ZOYA|  Marketing| 48000| 7200.0|55200.0|\n| KARAN|         HR| 53000| 7950.0|60950.0|\n|NAVEEN|Engineering| 70000|10500.0|80500.0|\n|FATIMA|  Marketing| 45000| 6750.0|51750.0|\n+------+-----------+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "#11. Add a new column Level :\n",
    "#“Senior” if salary > 60000\n",
    "#“Mid” if salary between 50000 and 60000\n",
    "#“Junior” otherwise\n",
    "from pyspark.sql.functions import when,col\n",
    "df.withColumn(\"Level\",when(col(\"Salary\") > 60000, \"Senior\").when((col(\"Salary\") >= 50000) & (col(\"Salary\") <= 60000), \"Mid\")\n",
    ".otherwise(\"Junior\")).show()\n",
    "\n",
    "#  12. Convert all names to uppercase.\n",
    "from pyspark.sql.functions import upper\n",
    "df=df.withColumn(\"Name\", upper(df[\"Name\"]))\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}