{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c407dfc-7781-4cf7-9841-b483680e81b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0x7c27ef93cd10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"EmployeeTimesheetAnalysis\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3debca19-11e4-4ba9-8d65-51384a3c92bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- EmployeeID: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Project: string (nullable = true)\n |-- WorkHours: integer (nullable = true)\n |-- WorkDate: date (nullable = true)\n |-- Location: string (nullable = true)\n |-- Mode: string (nullable = true)\n\nroot\n |-- EmployeeID: string (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Project: string (nullable = true)\n |-- WorkHours: integer (nullable = true)\n |-- WorkDate: date (nullable = true)\n |-- Location: string (nullable = true)\n |-- Mode: string (nullable = true)\n\n+----------+-----+----------+-------+---------+----------+---------+------+---------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|  Weekday|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|Wednesday|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote| Thursday|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|   Friday|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|   Friday|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|Wednesday|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote| Saturday|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Load with inferred schema\n",
    "timesheet_inferred = spark.read.csv(\"/FileStore/tables/employee_timesheet.csv\", header=True, inferSchema=True)\n",
    "timesheet_inferred.printSchema()\n",
    "\n",
    "# 2. Load with explicit schema\n",
    "custom_schema = StructType([\n",
    "    StructField(\"EmployeeID\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Project\", StringType(), True),\n",
    "    StructField(\"WorkHours\", IntegerType(), True),\n",
    "    StructField(\"WorkDate\", DateType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Mode\", StringType(), True)\n",
    "])\n",
    "\n",
    "timesheet_explicit = spark.read.csv(\"/FileStore/tables/employee_timesheet.csv\", header=True, schema=custom_schema)\n",
    "timesheet_explicit.printSchema()\n",
    "\n",
    "# 3. Add Weekday column\n",
    "timesheet_df = timesheet_explicit.withColumn(\"Weekday\", date_format(col(\"WorkDate\"), \"EEEE\"))\n",
    "timesheet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51801c5d-712b-49d0-be06-751be5461fa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n|EmployeeID| Name|TotalHours|\n+----------+-----+----------+\n|      E101|Anita|        17|\n|      E102|  Raj|        15|\n|      E104|Meena|         6|\n|      E103| John|         5|\n+----------+-----+----------+\n\n+----------+-----------------+\n|Department|         AvgHours|\n+----------+-----------------+\n|        IT|7.666666666666667|\n|        HR|              7.5|\n|   Finance|              5.0|\n+----------+-----------------+\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/pyspark/sql/connect/expressions.py:1017: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n|EmployeeID| Name|TotalHours|\n+----------+-----+----------+\n|      E101|Anita|        17|\n|      E102|  Raj|        15|\n+----------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Total work hours by employee\n",
    "total_hours_by_emp = timesheet_df.groupBy(\"EmployeeID\", \"Name\") \\\n",
    "    .agg(sum(\"WorkHours\").alias(\"TotalHours\")) \\\n",
    "    .orderBy(\"TotalHours\", ascending=False)\n",
    "total_hours_by_emp.show()\n",
    "\n",
    "# 5. Average work hours per department\n",
    "avg_hours_by_dept = timesheet_df.groupBy(\"Department\") \\\n",
    "    .agg(avg(\"WorkHours\").alias(\"AvgHours\")) \\\n",
    "    .orderBy(\"AvgHours\", ascending=False)\n",
    "avg_hours_by_dept.show()\n",
    "\n",
    "# 6. Top 2 employees by total hours using window\n",
    "window_spec = Window.orderBy(col(\"TotalHours\").desc())\n",
    "top_employees = total_hours_by_emp.withColumn(\"rank\", rank().over(window_spec)) \\\n",
    "    .filter(col(\"rank\") <= 2) \\\n",
    "    .drop(\"rank\")\n",
    "top_employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdac5014-cbe8-4353-a5ce-084cac5bca0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>Department</th><th>Project</th><th>WorkHours</th><th>WorkDate</th><th>Location</th><th>Mode</th><th>Weekday</th></tr></thead><tbody><tr><td>E102</td><td>Raj</td><td>HR</td><td>Beta</td><td>8</td><td>2024-05-04</td><td>Mumbai</td><td>Remote</td><td>Saturday</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E102",
         "Raj",
         "HR",
         "Beta",
         8,
         "2024-05-04",
         "Mumbai",
         "Remote",
         "Saturday"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Project",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WorkHours",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "WorkDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "Location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Mode",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Weekday",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>Department</th><th>Project</th><th>WorkHours</th><th>WorkDate</th><th>Location</th><th>Mode</th><th>Weekday</th><th>RunningTotalHours</th></tr></thead><tbody><tr><td>E101</td><td>Anita</td><td>IT</td><td>Alpha</td><td>8</td><td>2024-05-01</td><td>Bangalore</td><td>Remote</td><td>Wednesday</td><td>8</td></tr><tr><td>E101</td><td>Anita</td><td>IT</td><td>Alpha</td><td>9</td><td>2024-05-03</td><td>Bangalore</td><td>Remote</td><td>Friday</td><td>17</td></tr><tr><td>E102</td><td>Raj</td><td>HR</td><td>Beta</td><td>7</td><td>2024-05-01</td><td>Mumbai</td><td>Onsite</td><td>Wednesday</td><td>7</td></tr><tr><td>E102</td><td>Raj</td><td>HR</td><td>Beta</td><td>8</td><td>2024-05-04</td><td>Mumbai</td><td>Remote</td><td>Saturday</td><td>15</td></tr><tr><td>E103</td><td>John</td><td>Finance</td><td>Alpha</td><td>5</td><td>2024-05-02</td><td>Delhi</td><td>Remote</td><td>Thursday</td><td>5</td></tr><tr><td>E104</td><td>Meena</td><td>IT</td><td>Gamma</td><td>6</td><td>2024-05-03</td><td>Hyderabad</td><td>Onsite</td><td>Friday</td><td>6</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E101",
         "Anita",
         "IT",
         "Alpha",
         8,
         "2024-05-01",
         "Bangalore",
         "Remote",
         "Wednesday",
         8
        ],
        [
         "E101",
         "Anita",
         "IT",
         "Alpha",
         9,
         "2024-05-03",
         "Bangalore",
         "Remote",
         "Friday",
         17
        ],
        [
         "E102",
         "Raj",
         "HR",
         "Beta",
         7,
         "2024-05-01",
         "Mumbai",
         "Onsite",
         "Wednesday",
         7
        ],
        [
         "E102",
         "Raj",
         "HR",
         "Beta",
         8,
         "2024-05-04",
         "Mumbai",
         "Remote",
         "Saturday",
         15
        ],
        [
         "E103",
         "John",
         "Finance",
         "Alpha",
         5,
         "2024-05-02",
         "Delhi",
         "Remote",
         "Thursday",
         5
        ],
        [
         "E104",
         "Meena",
         "IT",
         "Gamma",
         6,
         "2024-05-03",
         "Hyderabad",
         "Onsite",
         "Friday",
         6
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Project",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WorkHours",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "WorkDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "Location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Mode",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Weekday",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "RunningTotalHours",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Filter weekend entries\n",
    "weekend_df = timesheet_df.filter((dayofweek(col(\"WorkDate\")) == 1) |  (dayofweek(col(\"WorkDate\")) == 7)    )\n",
    "display(weekend_df)\n",
    "\n",
    "# 8. Running total of hours per employee\n",
    "emp_window = Window.partitionBy(\"EmployeeID\").orderBy(\"WorkDate\")\n",
    "running_total_df = timesheet_df.withColumn(\"RunningTotalHours\", sum(\"WorkHours\").over(emp_window))\n",
    "display(running_total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3878414-51b5-4227-99d6-66780f554c42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+--------+-------+---------+\n|EmployeeID| Name|Department|DeptHead|Project|WorkHours|\n+----------+-----+----------+--------+-------+---------+\n|      E101|Anita|        IT|   Anand|  Alpha|        8|\n|      E103| John|   Finance|   Kamal|  Alpha|        5|\n|      E101|Anita|        IT|   Anand|  Alpha|        9|\n|      E104|Meena|        IT|   Anand|  Gamma|        6|\n|      E102|  Raj|        HR|  Shruti|   Beta|        7|\n|      E102|  Raj|        HR|  Shruti|   Beta|        8|\n+----------+-----+----------+--------+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Create department_location DataFrame \n",
    "dept_df = spark.read.csv(\"/FileStore/tables/department_location.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# 10. Join with timesheet data\n",
    "joined_df = timesheet_df.join(dept_df, \"Department\", \"left\") \\\n",
    "    .select(\"EmployeeID\", \"Name\", \"Department\", \"DeptHead\", \"Project\", \"WorkHours\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e89a87e-8068-4437-8d08-aa9414ea9762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+----+-----+\n|EmployeeID| Name|Alpha|Beta|Gamma|\n+----------+-----+-----+----+-----+\n|      E103| John|    5|   0|    0|\n|      E104|Meena|    0|   0|    6|\n|      E101|Anita|   17|   0|    0|\n|      E102|  Raj|    0|  15|    0|\n+----------+-----+-----+----+-----+\n\n+----------+------+-----+\n|EmployeeID|  Mode|Hours|\n+----------+------+-----+\n|      E104|Remote| NULL|\n|      E104|Onsite|    6|\n|      E101|Remote|   17|\n|      E101|Onsite| NULL|\n|      E102|Remote|    8|\n|      E102|Onsite|    7|\n|      E103|Remote|    5|\n|      E103|Onsite| NULL|\n+----------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 11. Pivot: total hours per employee per project\n",
    "pivot_df = timesheet_df.groupBy(\"EmployeeID\", \"Name\") \\\n",
    "    .pivot(\"Project\") \\\n",
    "    .agg(sum(\"WorkHours\").alias(\"TotalHours\")) \\\n",
    "    .fillna(0)\n",
    "pivot_df.show()\n",
    "\n",
    "# 12. Unpivot example\n",
    "unpivot_expr = \"stack(2, 'Remote', Remote, 'Onsite', Onsite) as (Mode, Hours)\"\n",
    "mode_hours_df = timesheet_df.groupBy(\"EmployeeID\") \\\n",
    "    .pivot(\"Mode\") \\\n",
    "    .agg(sum(\"WorkHours\")) \\\n",
    "    .selectExpr(\"EmployeeID\", unpivot_expr)\n",
    "mode_hours_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a9a2ab-53be-477a-a6f1-45944dcceb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|  Weekday|WorkloadCategory|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|Wednesday|            Full|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote| Thursday|         Partial|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|   Friday|            Full|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|   Friday|         Partial|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|Wednesday|         Partial|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote| Saturday|            Full|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 13. Create workload_tag UDF\n",
    "def workload_tag(hours):\n",
    "    if hours >= 8: return \"Full\"\n",
    "    elif hours >= 4: return \"Partial\"\n",
    "    else: return \"Light\"\n",
    "\n",
    "workload_udf = udf(workload_tag, StringType())\n",
    "\n",
    "# 14. Add WorkloadCategory column\n",
    "timesheet_df = timesheet_df.withColumn(\"WorkloadCategory\", workload_udf(col(\"WorkHours\")))\n",
    "timesheet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd50cd3d-b835-4898-8a13-4ab3d2178489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 15. Introduce nulls in Mode\n",
    "import random\n",
    "timesheet_with_nulls = timesheet_df.withColumn(\"Mode\", \n",
    "    when(rand() > 0.8, None).otherwise(col(\"Mode\")))\n",
    "\n",
    "# 16. Fill nulls with \"Not Provided\"\n",
    "timesheet_filled = timesheet_with_nulls.fillna(\"Not Provided\", subset=[\"Mode\"])\n",
    "\n",
    "# 17. Drop rows where WorkHours < 4\n",
    "timesheet_clean = timesheet_filled.filter(col(\"WorkHours\") >= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d4fa42-7fa2-44e8-aae0-bf37d36cedb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+------------+----------------+------------+\n|EmployeeID| Name|RemoteCount|TotalEntries|RemotePercentage|RemoteWorker|\n+----------+-----+-----------+------------+----------------+------------+\n|      E101|Anita|          2|           2|             1.0|         Yes|\n|      E103| John|          1|           1|             1.0|         Yes|\n|      E104|Meena|          0|           1|             0.0|          No|\n|      E102|  Raj|          1|           2|             0.5|          No|\n+----------+-----+-----------+------------+----------------+------------+\n\n+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+----------+\n|EmployeeID| Name|Department|Project|WorkHours|  WorkDate| Location|  Mode|  Weekday|WorkloadCategory|ExtraHours|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+----------+\n|      E101|Anita|        IT|  Alpha|        8|2024-05-01|Bangalore|Remote|Wednesday|            Full|         0|\n|      E103| John|   Finance|  Alpha|        5|2024-05-02|    Delhi|Remote| Thursday|         Partial|         0|\n|      E101|Anita|        IT|  Alpha|        9|2024-05-03|Bangalore|Remote|   Friday|            Full|         1|\n|      E104|Meena|        IT|  Gamma|        6|2024-05-03|Hyderabad|Onsite|   Friday|         Partial|         0|\n|      E102|  Raj|        HR|   Beta|        7|2024-05-01|   Mumbai|Onsite|Wednesday|         Partial|         0|\n|      E102|  Raj|        HR|   Beta|        8|2024-05-04|   Mumbai|Remote| Saturday|            Full|         0|\n+----------+-----+----------+-------+---------+----------+---------+------+---------+----------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 18. Mark \"Remote Worker\" if >80% entries are Remote\n",
    "remote_workers = timesheet_df.groupBy(\"EmployeeID\", \"Name\") \\\n",
    "    .agg(\n",
    "        count(when(col(\"Mode\") == \"Remote\", 1)).alias(\"RemoteCount\"),\n",
    "        count(\"*\").alias(\"TotalEntries\")\n",
    "    ) \\\n",
    "    .withColumn(\"RemotePercentage\", col(\"RemoteCount\")/col(\"TotalEntries\")) \\\n",
    "    .withColumn(\"RemoteWorker\", \n",
    "        when(col(\"RemotePercentage\") > 0.8, \"Yes\").otherwise(\"No\"))\n",
    "remote_workers.show()\n",
    "\n",
    "# 19. Add ExtraHours column\n",
    "timesheet_df = timesheet_df.withColumn(\"ExtraHours\", \n",
    "    when(col(\"WorkHours\") > 8, col(\"WorkHours\") - 8).otherwise(0))\n",
    "timesheet_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8920a61d-fe3b-46a8-b240-5cc9f8511699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmployeeID</th><th>Name</th><th>Department</th><th>Project</th><th>WorkHours</th><th>WorkDate</th><th>Location</th><th>Mode</th><th>Weekday</th></tr></thead><tbody><tr><td>E101</td><td>Anita</td><td>IT</td><td>Alpha</td><td>8</td><td>2024-05-01</td><td>Bangalore</td><td>Remote</td><td>Wednesday</td></tr><tr><td>E103</td><td>John</td><td>Finance</td><td>Alpha</td><td>5</td><td>2024-05-02</td><td>Delhi</td><td>Remote</td><td>Thursday</td></tr><tr><td>E101</td><td>Anita</td><td>IT</td><td>Alpha</td><td>9</td><td>2024-05-03</td><td>Bangalore</td><td>Remote</td><td>Friday</td></tr><tr><td>E104</td><td>Meena</td><td>IT</td><td>Gamma</td><td>6</td><td>2024-05-03</td><td>Hyderabad</td><td>Onsite</td><td>Friday</td></tr><tr><td>E102</td><td>Raj</td><td>HR</td><td>Beta</td><td>7</td><td>2024-05-01</td><td>Mumbai</td><td>Onsite</td><td>Wednesday</td></tr><tr><td>E102</td><td>Raj</td><td>HR</td><td>Beta</td><td>8</td><td>2024-05-04</td><td>Mumbai</td><td>Remote</td><td>Saturday</td></tr><tr><td>E105</td><td>Intern1</td><td>IT</td><td>Alpha</td><td>4</td><td>2024-05-05</td><td>Bangalore</td><td>Onsite</td><td>null</td></tr><tr><td>E106</td><td>Intern2</td><td>HR</td><td>Beta</td><td>5</td><td>2024-05-05</td><td>Mumbai</td><td>Remote</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E101",
         "Anita",
         "IT",
         "Alpha",
         8,
         "2024-05-01",
         "Bangalore",
         "Remote",
         "Wednesday"
        ],
        [
         "E103",
         "John",
         "Finance",
         "Alpha",
         5,
         "2024-05-02",
         "Delhi",
         "Remote",
         "Thursday"
        ],
        [
         "E101",
         "Anita",
         "IT",
         "Alpha",
         9,
         "2024-05-03",
         "Bangalore",
         "Remote",
         "Friday"
        ],
        [
         "E104",
         "Meena",
         "IT",
         "Gamma",
         6,
         "2024-05-03",
         "Hyderabad",
         "Onsite",
         "Friday"
        ],
        [
         "E102",
         "Raj",
         "HR",
         "Beta",
         7,
         "2024-05-01",
         "Mumbai",
         "Onsite",
         "Wednesday"
        ],
        [
         "E102",
         "Raj",
         "HR",
         "Beta",
         8,
         "2024-05-04",
         "Mumbai",
         "Remote",
         "Saturday"
        ],
        [
         "E105",
         "Intern1",
         "IT",
         "Alpha",
         4,
         "2024-05-05",
         "Bangalore",
         "Onsite",
         null
        ],
        [
         "E106",
         "Intern2",
         "HR",
         "Beta",
         5,
         "2024-05-05",
         "Mumbai",
         "Remote",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmployeeID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Project",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WorkHours",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "WorkDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "Location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Mode",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Weekday",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original count: 8, Deduped count: 8\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Define the complete schema\n",
    "timesheet_schema = StructType([\n",
    "    StructField(\"EmployeeID\", StringType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Project\", StringType(), True),\n",
    "    StructField(\"WorkHours\", IntegerType(), True),\n",
    "    StructField(\"WorkDate\", DateType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Mode\", StringType(), True),\n",
    "    StructField(\"Weekday\", StringType(), True)\n",
    "])\n",
    "\n",
    "# 20. Append dummy intern data with explicit schema\n",
    "intern_data = [\n",
    "    (\"E105\", \"Intern1\", \"IT\", \"Alpha\", 4, date(2024, 5, 5), \"Bangalore\", \"Onsite\", None),\n",
    "    (\"E106\", \"Intern2\", \"HR\", \"Beta\", 5, date(2024, 5, 5), \"Mumbai\", \"Remote\", None)\n",
    "]\n",
    "\n",
    "\n",
    "intern_df = spark.createDataFrame(intern_data, schema=timesheet_schema)\n",
    "timesheet_df = timesheet_df.select([col(c).cast(timesheet_schema[c].dataType) for c in timesheet_schema.names])\n",
    "combined_df = timesheet_df.unionByName(intern_df)\n",
    "display(combined_df)\n",
    "\n",
    "# 21. Remove duplicates\n",
    "deduped_df = combined_df.dropDuplicates()\n",
    "print(f\"Original count: {combined_df.count()}, Deduped count: {deduped_df.count()}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Employee Timesheet System",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}